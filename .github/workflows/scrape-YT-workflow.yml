name: Scrape YT Trending Captions
on:
  schedule:
    - cron: '0 12 * * *'
  push:

jobs:
  query-page:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: Install Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.8
      - name: Build Env
        uses: ./.github/actions/build_py_env
        with:
          requirements: data/setup/scraper-reqs.txt
      - name: Build gcloud-service-keys
        run: printf '{%s}' "${{ secrets.GCLOUD_SERVICE_KEY }}" > data/setup/gcloud-service-keys.json
      - name: Init gcloud-service-keys
        run: export GOOGLE_APPLICATION_CREDENTIALS = "data/setup/gcloud-service-keys.json"
      - name: Build api-keys
        run: printf '{"yt-data-api-key":"%s"}\n' "${{ secrets.YOUTUBE_API_KEYS }}" > data/setup/api-keys.json
      - name: Run Scraper Script
        run: pipenv run python code/query-captions-on-trending-videos.py
      - name: Commit
        uses: ./.github/actions/commit
        with:
          message: new yt-trending scraped data
          what: data/*.csv